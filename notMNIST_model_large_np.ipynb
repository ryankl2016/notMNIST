{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context\n",
    "\n",
    "This dataset was created by Yaroslav Bulatov by taking some publicly available fonts and extracting glyphs from them to make a dataset similar to MNIST. There are 10 classes, with letters A-J.\n",
    "\n",
    "## Content\n",
    "\n",
    "A set of training and test images of letters from A to J on various typefaces. The images size is 28x28 pixels.\n",
    "\n",
    "## Acknowledgements\n",
    "\n",
    "The dataset can be found on Tensorflow github page as well as on the blog from Yaroslav, here.\n",
    "\n",
    "## Inspiration\n",
    "\n",
    "This is a pretty good dataset to train classifiers! According to Yaroslav:\n",
    "\n",
    "Judging by the examples, one would expect this to be a harder task than MNIST. This seems to be the case -- logistic regression on top of stacked auto-encoder with fine-tuning gets about 89% accuracy whereas same approach gives got 98% on MNIST. Dataset consists of small hand-cleaned part, about 19k instances, and large uncleaned dataset, 500k instances. Two parts have approximately 0.5% and 6.5% label error rate. I got this by looking through glyphs and counting how often my guess of the letter didn't match it's unicode value in the font file.\n",
    "Enjoy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryanleung/anaconda3/envs/py3/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the path names to images and labeling into numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>112</td>\n",
       "      <td>149</td>\n",
       "      <td>180</td>\n",
       "      <td>199</td>\n",
       "      <td>214</td>\n",
       "      <td>229</td>\n",
       "      <td>224</td>\n",
       "      <td>215</td>\n",
       "      <td>197</td>\n",
       "      <td>176</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>110</td>\n",
       "      <td>...</td>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "      <td>68</td>\n",
       "      <td>34</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132</td>\n",
       "      <td>243</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>254</td>\n",
       "      <td>240</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>199</td>\n",
       "      <td>215</td>\n",
       "      <td>231</td>\n",
       "      <td>235</td>\n",
       "      <td>240</td>\n",
       "      <td>246</td>\n",
       "      <td>254</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>251</td>\n",
       "      <td>243</td>\n",
       "      <td>234</td>\n",
       "      <td>227</td>\n",
       "      <td>220</td>\n",
       "      <td>217</td>\n",
       "      <td>170</td>\n",
       "      <td>120</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9   ...    775  776  777  \\\n",
       "0  112  149  180  199  214  229  224  215  197  176   ...      0    0    0   \n",
       "1    0    0    4    1    0    0    1    0   20  110   ...     84   84   68   \n",
       "2    0    0    0    0    0    0    0    1    2    0   ...     10    4    0   \n",
       "3  132  243  255  255  255  255  255  255  255  255   ...    255  255  255   \n",
       "4  199  215  231  235  240  246  254  255  255  255   ...    255  251  243   \n",
       "\n",
       "   778  779  780  781  782  783  labels  \n",
       "0    4    2    0    0    0    0       I  \n",
       "1   34    4    0    0    0    0       I  \n",
       "2    0    0    0    0    0    0       I  \n",
       "3  255  255  255  255  254  240       I  \n",
       "4  234  227  220  217  170  120       I  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parentDir = 'notMNIST_large/'\n",
    "labels = []\n",
    "images = []\n",
    "total = 0\n",
    "bad = 0\n",
    "for folder in os.listdir(parentDir):\n",
    "    if folder != '.DS_Store':\n",
    "        if total % 10000 == 0:\n",
    "            print(total, bad)\n",
    "            total += 1\n",
    "        try:\n",
    "            for file in os.listdir(parentDir + folder):\n",
    "                img = Image.open(parentDir + folder + '/' + file)\n",
    "                img = np.asarray(img).flatten()\n",
    "                \n",
    "                images.append(np.asarray(img))\n",
    "                labels.append(folder)\n",
    "        except:\n",
    "            bad += 1\n",
    "            pass\n",
    "dataset = pd.DataFrame(images)\n",
    "dataset['labels'] = np.asarray(labels)\n",
    "dataset.head()\n",
    "\n",
    "\n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15933\n",
      "18726\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))\n",
    "print(np.sum([len(os.listdir(parentDir+x)) for x in os.listdir(parentDir) if x != '.DS_Store']))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15933\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set batch size and epochs\n",
    "\n",
    "Don't want batch size to be too large or not too small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "num_epochs = 100\n",
    "def input_func(features, labels, batch_size):\n",
    "    \n",
    "    def parser(image, label): \n",
    "        \n",
    "        img = tf.image.decode_png(tf.read_file(image))\n",
    "        img = tf.image.resize_images(img, tf.constant([1, 784]))\n",
    "        img = tf.reshape(img, [28, 28, 1])\n",
    "        img = tf.cast(img, tf.float32, \"cast\")\n",
    "\n",
    "        return img, label\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((features, labels))\n",
    "    dataset = dataset.map(parser)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model architecture\n",
    "Uses a two layer, each layer consisting of a convolutional and pooling layer, architecture. (Same architecture as original MNIST CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_model(features, labels, mode, params):\n",
    "    #initialize input by reshaping and casting for network\n",
    "    #img = tf.image.decode_png(tf.read_file(features['x'][0]))\n",
    "    # img = np.array( img, dtype='uint8' ).flatten()\n",
    "    \n",
    "    # FIRST LAYER\n",
    "    # ---conv layer with 32 filters, 5x5 kernel, and relu activation\n",
    "    # ---pool layer with 2x2 pool window and stride of 2x2\n",
    "    \n",
    "    input_layer = tf.reshape(features['x'], [-1, 28, 28, 1])\n",
    "    input_layer = tf.cast(input_layer, tf.float32, \"cast\")\n",
    "    conv1 = tf.layers.conv2d(inputs=input_layer, filters=32, kernel_size=(5, 5), padding=\"same\", activation=tf.nn.relu)\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=(2, 2), strides=(2, 2))\n",
    "    \n",
    "    # SECOND LAYER\n",
    "    # ---conv layer with 64 filters, 5x5 kernel, and relu activation\n",
    "    # ---pool layer with 2x2 pool window and stride of 2x2\n",
    "    conv2 = tf.layers.conv2d(inputs=pool1, filters=64, kernel_size=(5, 5), padding=\"same\", activation=tf.nn.relu)\n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=(2, 2), strides=(2, 2))\n",
    "    \n",
    "    # DENSE LAYER\n",
    "    # ---flatten output into vector\n",
    "    # ---dropout to prevent overfitting\n",
    "    pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "    dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "    dropout = tf.layers.dropout(inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "    \n",
    "    logits = tf.layers.dense(inputs=dropout, units=10)\n",
    "    predictions = {\n",
    "        \"classes\": tf.argmax(input=logits, axis=1),\n",
    "        \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "    }\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "    \n",
    "    onehot_labels = tf.one_hot(indices=tf.cast(labels, tf.int32), depth=10)\n",
    "    onehot_labels = tf.reshape(onehot_labels, [-1, 10])\n",
    "    loss = tf.losses.softmax_cross_entropy(onehot_labels=onehot_labels, logits=logits)\n",
    "#     loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "        train_op = optimizer.minimize(loss=loss,global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "    print(labels.shape)\n",
    "    print(predictions[\"classes\"].shape)\n",
    "    eval_metric_ops = {\"accuracy\": tf.metrics.accuracy(labels=labels, predictions=predictions[\"classes\"])}\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Evaluating\n",
    "-> split data into train and test (2:1) <br>\n",
    "-> instantiate model with my_model as cnn <br>\n",
    "-> convert dataset (np array) to dataframe to use pd.factorize to get integer labels, then convert back to np array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/th/svpqqvhs62790bm9gczzcth40000gn/T/tmpv9ue6kpa\n",
      "INFO:tensorflow:Using config: {'_log_step_count_steps': 100, '_save_checkpoints_secs': 600, '_is_chief': True, '_service': None, '_keep_checkpoint_every_n_hours': 10000, '_session_config': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1a418b9cf8>, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_task_id': 0, '_save_checkpoints_steps': None, '_save_summary_steps': 100, '_model_dir': '/var/folders/th/svpqqvhs62790bm9gczzcth40000gn/T/tmpv9ue6kpa', '_master': '', '_tf_random_seed': None, '_evaluation_master': '', '_task_type': 'worker', '_keep_checkpoint_max': 5, '_train_distribute': None, '_global_id_in_cluster': 0}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function my_model at 0x111b6ac80>) includes params argument, but params are not passed to Estimator.\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [2 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]] [7 5 5 ... 0 9 5]\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/th/svpqqvhs62790bm9gczzcth40000gn/T/tmpv9ue6kpa/model.ckpt.\n",
      "INFO:tensorflow:loss = 100.167786, step = 1\n",
      "INFO:tensorflow:global_step/sec: 21.3181\n",
      "INFO:tensorflow:loss = 1.4613235, step = 101 (4.692 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.7108\n",
      "INFO:tensorflow:loss = 0.5883642, step = 201 (4.606 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8104\n",
      "INFO:tensorflow:loss = 1.016849, step = 301 (4.585 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.7625\n",
      "INFO:tensorflow:loss = 1.3120388, step = 401 (4.595 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.7168\n",
      "INFO:tensorflow:loss = 0.25644398, step = 501 (4.605 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.4999\n",
      "INFO:tensorflow:loss = 0.46502614, step = 601 (4.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.0914\n",
      "INFO:tensorflow:loss = 0.42538345, step = 701 (3.691 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.1913\n",
      "INFO:tensorflow:loss = 0.95975816, step = 801 (4.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.7807\n",
      "INFO:tensorflow:loss = 0.17410241, step = 901 (4.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.1783\n",
      "INFO:tensorflow:loss = 0.25391895, step = 1001 (4.136 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.9245\n",
      "INFO:tensorflow:loss = 0.628788, step = 1101 (4.180 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.0518\n",
      "INFO:tensorflow:loss = 0.582621, step = 1201 (4.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.9422\n",
      "INFO:tensorflow:loss = 0.6081987, step = 1301 (4.009 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.1132\n",
      "INFO:tensorflow:loss = 0.20151293, step = 1401 (4.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.995\n",
      "INFO:tensorflow:loss = 0.08137355, step = 1501 (4.168 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.8911\n",
      "INFO:tensorflow:loss = 0.63903725, step = 1601 (4.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.4367\n",
      "INFO:tensorflow:loss = 0.15933737, step = 1701 (4.092 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.3221\n",
      "INFO:tensorflow:loss = 0.12891729, step = 1801 (3.949 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.2737\n",
      "INFO:tensorflow:loss = 0.14718193, step = 1901 (4.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.6919\n",
      "INFO:tensorflow:loss = 0.7498803, step = 2001 (4.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.7421\n",
      "INFO:tensorflow:loss = 0.44207907, step = 2101 (4.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.7573\n",
      "INFO:tensorflow:loss = 0.49256474, step = 2201 (4.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.1766\n",
      "INFO:tensorflow:loss = 0.17811649, step = 2301 (4.136 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.9433\n",
      "INFO:tensorflow:loss = 0.31453973, step = 2401 (4.176 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.8125\n",
      "INFO:tensorflow:loss = 0.59571207, step = 2501 (4.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 25.1528\n",
      "INFO:tensorflow:loss = 0.10907528, step = 2601 (3.976 sec)\n",
      "INFO:tensorflow:global_step/sec: 26.897\n",
      "INFO:tensorflow:loss = 0.9431734, step = 2701 (3.718 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.1403\n",
      "INFO:tensorflow:loss = 0.27437684, step = 2801 (3.685 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.8905\n",
      "INFO:tensorflow:loss = 0.36090615, step = 2901 (4.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.4024\n",
      "INFO:tensorflow:loss = 0.42263126, step = 3001 (4.274 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.5514\n",
      "INFO:tensorflow:loss = 0.051244713, step = 3101 (4.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.4917\n",
      "INFO:tensorflow:loss = 0.15761968, step = 3201 (4.257 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.6447\n",
      "INFO:tensorflow:loss = 0.52248, step = 3301 (4.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.3856\n",
      "INFO:tensorflow:loss = 0.20119362, step = 3401 (4.276 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.5807\n",
      "INFO:tensorflow:loss = 0.69517714, step = 3501 (4.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.061\n",
      "INFO:tensorflow:loss = 0.16204174, step = 3601 (4.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.7404\n",
      "INFO:tensorflow:loss = 0.16545674, step = 3701 (4.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.9345\n",
      "INFO:tensorflow:loss = 0.15944263, step = 3801 (4.178 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.9966\n",
      "INFO:tensorflow:loss = 0.37405187, step = 3901 (4.167 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.6513\n",
      "INFO:tensorflow:loss = 0.5079212, step = 4001 (4.415 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.25\n",
      "INFO:tensorflow:loss = 0.018682571, step = 4101 (4.939 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.8937\n",
      "INFO:tensorflow:loss = 0.023413736, step = 4201 (4.567 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.3234\n",
      "INFO:tensorflow:loss = 0.014995858, step = 4301 (4.921 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.9781\n",
      "INFO:tensorflow:loss = 0.124756545, step = 4401 (4.766 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.0706\n",
      "INFO:tensorflow:loss = 0.023852855, step = 4501 (4.746 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4357\n",
      "INFO:tensorflow:loss = 0.0071806726, step = 4601 (4.457 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.2123\n",
      "INFO:tensorflow:loss = 0.03464141, step = 4701 (4.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 21.9792\n",
      "INFO:tensorflow:loss = 0.042070605, step = 4801 (4.550 sec)\n",
      "INFO:tensorflow:global_step/sec: 20.8011\n",
      "INFO:tensorflow:loss = 0.04024623, step = 4901 (4.808 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into /var/folders/th/svpqqvhs62790bm9gczzcth40000gn/T/tmpv9ue6kpa/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.07425435.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "(?,)\n",
      "(?,)\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-06-22-07:48:02\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/th/svpqqvhs62790bm9gczzcth40000gn/T/tmpv9ue6kpa/model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-06-22-07:54:59\n",
      "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.9271586, global_step = 5000, loss = 0.26160794\n",
      "\n",
      "Test set accuracy: 0.927\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fetch the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset[[i for i in range(784)]], pd.factorize(dataset['labels'])[0], test_size=0.33, random_state=42)\n",
    "\n",
    "# Build CNN.\n",
    "classifier = tf.estimator.Estimator(model_fn=my_model)\n",
    "\n",
    "# Train the Model.\n",
    "X_train = np.asarray(X_train)\n",
    "y_train = np.asarray(y_train)\n",
    "\n",
    "X_test = np.asarray(X_test)\n",
    "y_test = np.asarray(y_test)\n",
    "\n",
    "print(X_train, y_train)\n",
    "\n",
    "train_input_func = tf.estimator.inputs.numpy_input_fn(x = {'x' : X_train}, \n",
    "                                                      y = y_train, \n",
    "                                                      batch_size = batch_size, \n",
    "                                                      num_epochs = num_epochs, \n",
    "                                                      shuffle = True\n",
    "                                                     )\n",
    "classifier.train(input_fn=train_input_func, steps = 5000)\n",
    "\n",
    "# Evaluate the model.\n",
    "eval_input_func = tf.estimator.inputs.numpy_input_fn(x = {'x' : X_test}, \n",
    "                                                      y = y_test, \n",
    "                                                      batch_size = batch_size, \n",
    "                                                      num_epochs = num_epochs, \n",
    "                                                      shuffle = True\n",
    "                                                     )\n",
    "eval_result = classifier.evaluate(input_fn=eval_input_func)\n",
    "\n",
    "print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['notMNIST_large/A/VW5pdmVyc0xULUV4dHJhQmxhY2tFeHQub3Rm.png'\n",
      " 'notMNIST_large/F/Q3JheW9uIE5vcm1hbC50dGY=.png'\n",
      " 'notMNIST_large/B/QnVyb2tyYXQtT25lLm90Zg==.png' ...\n",
      " 'notMNIST_large/E/SW5zdGFsbGF0aW9uIFNTaSBCb2xkLnR0Zg==.png'\n",
      " 'notMNIST_large/H/QmF1ZXIgQm9kb25pIEl0YWxpYy5wZmI=.png'\n",
      " 'notMNIST_large/I/VHJpYW5nZWwudHRm.png'] 174610\n",
      "[2 3 9 ... 8 4 0] 174610\n"
     ]
    }
   ],
   "source": [
    "print(X_test, len(X_test))\n",
    "print(y_test, len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 2 0] 10675\n",
      "[7 5 5 ... 0 9 5] 10675\n"
     ]
    }
   ],
   "source": [
    "print(X_train, len(X_train))\n",
    "print(y_train, len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
